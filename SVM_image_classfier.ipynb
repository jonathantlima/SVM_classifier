{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "v9kw31vCbLSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.color import rgb2gray\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "VUWV8FO7bMxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni0AFfwPbf5n",
        "outputId": "fdef34e2-8b2c-492e-f219-bcae002e8ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparing Data**"
      ],
      "metadata": {
        "id": "C0thMnOaYXBz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOnIgbbFUYoF"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/gdrive/MyDrive/CCI/TCC/BaseImagensTecido/FS_1'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `listdir()` returns a list containing all directories within `data_dir` which will be used as the classes (`categories`) of the model.\n",
        "The word `classes` would be more adequate, but `class` is a reserved word so then using `categories` prevents confusion."
      ],
      "metadata": {
        "id": "XCCKdo2bdyfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = os.listdir(data_dir) # Returns the classes of the model\n",
        "print(categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "741omtpFbkHa",
        "outputId": "daac8752-c74b-4dd6-e958-b27e0063cac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RC', 'LV', 'LH', 'OK']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following snippet presents a way to load the custmized dataset (`dataset loading`) from an specific directory. Libraries like `TensorFlow`, `PyTorch`, `Fast.ai` e `YOLO` have already methods to load a dataset, however, the strategy is very similar. The function `load_image_dataset()` was created so that this chunck of code could be reutilized whenever needed."
      ],
      "metadata": {
        "id": "fHNygQSdesOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_dataset(directory, dimensions):\n",
        "\n",
        "  '''\n",
        "  This function receives a directory composed of directories which\n",
        "  contain de image data. Each inside directory stand for a classification\n",
        "  category. The function returns two arrays: data and labels, already\n",
        "  transformed into numpy array object-type.\n",
        "\n",
        "  The labels are identified by integer numbers following Python native\n",
        "  indexation, however, it can converted to a string class.\n",
        "\n",
        "  Two argument are required:\n",
        "      directory, dimensions\n",
        "\n",
        "  The dimensions will be used for resizing the images. After that, the flatten()\n",
        "  method is used to convert images into arrays, i.e., from 2D objects into a\n",
        "  single array (1D) object.\n",
        "\n",
        "  By using the command `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)` the images is\n",
        "  converted from 3 chanels to 1 chanel (gray). This operation is important so\n",
        "  the data is generated correctly.\n",
        "\n",
        "  Uncomment the first lines of the code if you want to reuse this function in\n",
        "  another script or notebook.\n",
        "  '''\n",
        "\n",
        "  #import os\n",
        "  #from skimage.io import imread\n",
        "  #from skimage.transform import resize\n",
        "  #import numpy as np\n",
        "\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  for category_idx, category in enumerate(categories):\n",
        "      for file in os.listdir(os.path.join(data_dir, category)):\n",
        "          img_path = os.path.join(data_dir, category, file)\n",
        "          img = cv2.imread(img_path)\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "          img = cv2.resize(img, (128, 128))\n",
        "          img = img / 255\n",
        "          img = img.flatten()\n",
        "          data.append(img) # img.flatten() Converte cada imagem para um array\n",
        "          labels.append(category_idx) # Atribui uma classe numérica\n",
        "\n",
        "  data = np.array(data) # Converte a lista em um array\n",
        "  labels = np.array(labels) # Converte a lista em um array\n",
        "\n",
        "  print(f'There were found {len(data)} images and {len(categories)} labels.')\n",
        "\n",
        "  return data, labels"
      ],
      "metadata": {
        "id": "d6MeNsrpbsLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height, width = 128, 128\n",
        "resize_dimensions = (height, width)\n",
        "data, labels = load_image_dataset(data_dir, resize_dimensions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESbyBKVzkU16",
        "outputId": "7ca44a57-3d8b-427b-cf28-031d64ed80a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were found 342 images and 4 labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Processing**"
      ],
      "metadata": {
        "id": "185V7jcvYcNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `train_test_split()` from sci-kit learn is well largely used to split a dataset between trainning and test (or validation). The argument `shuffle=True` guarantees the data will be shuffled prior to division, thus minimizing any bias. The argument `stratify=labels` states that examples from both classes will exist in derived dataset."
      ],
      "metadata": {
        "id": "6tOpiqB6pQ2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data, labels,\n",
        "                                                    test_size=0.2, # Test dataset = 20% of data\n",
        "                                                    shuffle=True, # Prevents bias\n",
        "                                                    stratify=labels)"
      ],
      "metadata": {
        "id": "xBV8QrghYcwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "0TsQcuzJYj4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The object `classifier` is created as an instance from class `SVC()`. Initially, the `classifier` is created using default arguments.\n",
        "\n",
        "The variable `parameters` contains two keys. The first value of the pair (key, value) possesses three possible values for the `gamma` argument, while the second value holds four possible values for the argument `C`. Both are entries for `SVC()`. Then, twelve `classifiers` (3 `gammas` X 4 `C`) are generated.\n",
        "\n",
        "Class `GridSearchCV()` receives the forementioned arguments and creates the twelve classifiers. The method `.fit()` performs the training of those 12 `classifiers`. Finally, the atribute `best_estimator_` finds the best `classifier`. The models are _Support Vector Machine_ `SVM` ML models."
      ],
      "metadata": {
        "id": "9qkmu4yc4Jv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVC()"
      ],
      "metadata": {
        "id": "ecLd71F3YkKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]"
      ],
      "metadata": {
        "id": "8yBVgiBv5A7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(classifier, parameters)"
      ],
      "metadata": {
        "id": "pdMJ3AvP6HM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "js8aBc0e6qb9",
        "outputId": "452ea6ce-8ac1-4876-e6af-d993be23c7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid=[{'C': [1, 10, 100, 1000],\n",
              "                          'gamma': [0.01, 0.001, 0.0001]}])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
              "             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000],\n",
              "                          &#x27;gamma&#x27;: [0.01, 0.001, 0.0001]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
              "             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000],\n",
              "                          &#x27;gamma&#x27;: [0.01, 0.001, 0.0001]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Performance**"
      ],
      "metadata": {
        "id": "A5yhtHtoYowa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_estimator = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "qhfNg3ArYp1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_estimator.predict(x_test)"
      ],
      "metadata": {
        "id": "hmSNQLRlsbZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "id": "dCZ5gUXcs0ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Score: {}%'.format(round(score * 100)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O97kLEhtDtC",
        "outputId": "ed41f99d-9488-4bc6-97c5-85ea0826094d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DatwzuuxubKh",
        "outputId": "3f5086bf-dff1-43b0-a460-799cfa1f24b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.89      1.00      0.94         8\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       1.00      0.98      0.99        48\n",
            "\n",
            "    accuracy                           0.99        69\n",
            "   macro avg       0.97      0.99      0.98        69\n",
            "weighted avg       0.99      0.99      0.99        69\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells an image file is read and tested using the best_estimator `classifier`. The input shall mirror the inputs used to train the model, thus a few operations are required. The result is an array containing the image pixels values divided by 255 and with one single chanel.\n",
        "\n",
        "This data is not readable by te model, so it is necessary to `reshape` the data into an array of arrays by applying the method `reshape(1, -1)`."
      ],
      "metadata": {
        "id": "3PNUssihACYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = os.path.join('/content/gdrive/MyDrive/CCI/TCC/BaseImagensTecido/FS_1/LH/LH_imgt02_hflip.bmp')\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = cv2.resize(img, (128, 128))\n",
        "img = img / 255\n",
        "img = img.flatten()"
      ],
      "metadata": {
        "id": "3cP4a237uzGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = best_estimator.predict(img.reshape(1, -1))\n",
        "print(prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTCBv-u2vjRi",
        "outputId": "2db49bc1-014a-4a82-ca9f-68ac3693ab0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmXuJY_y9q0m",
        "outputId": "597c9776-e364-479f-97bb-9d089967ad2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.18039216, 0.17647059, 0.19215686, ..., 0.20392157, 0.20392157,\n",
              "       0.22352941])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.reshape(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bk8za449szm",
        "outputId": "a967cc59-3167-4056-e158-facc6feb1597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18039216, 0.17647059, 0.19215686, ..., 0.20392157, 0.20392157,\n",
              "        0.22352941]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the model**"
      ],
      "metadata": {
        "id": "2UTImQgW9zji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(best_estimator, open('./model.p', 'wb'))"
      ],
      "metadata": {
        "id": "SoIaRmwg8VpQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}